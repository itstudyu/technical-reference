<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="Complete guide to Large Language Models (LLMs) - architecture, training, applications, and implementation"
    />
    <title>Large Language Models (LLM) | Technical Reference</title>
    <link rel="stylesheet" href="styles/main.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
  </head>
  <body>
    <!-- Skip to main content for accessibility -->
    <a href="#main-content" class="skip-link">Skip to main content</a>

    <!-- Header -->
    <header class="header">
      <div class="container">
        <div class="header-content">
          <div class="logo">
            <h1><a href="index.html">Tech Reference</a></h1>
          </div>
          <nav class="nav" aria-label="Main navigation">
            <ul class="nav-list">
              <li><a href="index.html" class="nav-link">Home</a></li>
              <li class="nav-dropdown">
                <button class="nav-link dropdown-toggle" aria-expanded="false">
                  Networking
                  <svg
                    class="dropdown-icon"
                    width="16"
                    height="16"
                    viewBox="0 0 16 16"
                    fill="currentColor"
                  >
                    <path d="M8 10.5L3.5 6h9L8 10.5z" />
                  </svg>
                </button>
                <ul class="dropdown-menu">
                  <li><a href="proxy.html" class="dropdown-link">Proxy</a></li>
                  <li>
                    <a href="reverse-proxy.html" class="dropdown-link"
                      >Reverse Proxy</a
                    >
                  </li>
                </ul>
              </li>
              <li class="nav-dropdown">
                <button class="nav-link dropdown-toggle" aria-expanded="false">
                  AI/ML
                  <svg
                    class="dropdown-icon"
                    width="16"
                    height="16"
                    viewBox="0 0 16 16"
                    fill="currentColor"
                  >
                    <path d="M8 10.5L3.5 6h9L8 10.5z" />
                  </svg>
                </button>
                <ul class="dropdown-menu">
                  <li>
                    <a href="llm.html" class="dropdown-link active">LLM</a>
                  </li>
                  <li>
                    <a href="fine-tuning.html" class="dropdown-link"
                      >Fine Tuning</a
                    >
                  </li>
                  <li><a href="rag.html" class="dropdown-link">RAG</a></li>
                </ul>
              </li>
            </ul>
          </nav>
          <button class="mobile-menu-toggle" aria-label="Toggle mobile menu">
            <span></span>
            <span></span>
            <span></span>
          </button>
        </div>
      </div>
    </header>

    <!-- Main Content -->
    <main id="main-content" class="main">
      <!-- Page Header -->
      <section class="page-header">
        <div class="container">
          <div class="page-header-content">
            <h1 class="page-title">Large Language Models (LLM)</h1>
            <p class="page-subtitle">
              Understanding the architecture, training, and applications of
              modern large language models
            </p>
          </div>
        </div>
      </section>

      <!-- Content Container -->
      <div class="content-container">
        <div class="container">
          <div class="content-layout">
            <!-- Table of Contents -->
            <aside class="toc-sidebar">
              <div class="toc-container">
                <h2 class="toc-title">Contents</h2>
                <nav class="toc">
                  <ul class="toc-list">
                    <li><a href="#overview" class="toc-link">Overview</a></li>
                    <li>
                      <a href="#architecture" class="toc-link">Architecture</a>
                    </li>
                    <li>
                      <a href="#training" class="toc-link">Training Process</a>
                    </li>
                    <li>
                      <a href="#models" class="toc-link">Popular Models</a>
                    </li>
                    <li>
                      <a href="#applications" class="toc-link">Applications</a>
                    </li>
                    <li>
                      <a href="#challenges" class="toc-link">Challenges</a>
                    </li>
                    <li>
                      <a href="#implementation" class="toc-link"
                        >Implementation</a
                      >
                    </li>
                    <li>
                      <a href="#best-practices" class="toc-link"
                        >Best Practices</a
                      >
                    </li>
                  </ul>
                </nav>
              </div>
            </aside>

            <!-- Main Content -->
            <article class="content">
              <!-- Overview Section -->
              <section id="overview" class="content-section">
                <h2 class="section-title">What are Large Language Models?</h2>
                <p class="section-intro">
                  Large Language Models (LLMs) are artificial intelligence
                  systems trained on vast amounts of text data to understand and
                  generate human-like language. They use deep learning
                  architectures, primarily transformers, to process and generate
                  text at scale.
                </p>

                <div class="definition-box">
                  <h3>Key Characteristics</h3>
                  <ul>
                    <li>
                      <strong>Scale:</strong> Trained on billions to trillions
                      of parameters
                    </li>
                    <li>
                      <strong>Generative:</strong> Can produce coherent,
                      contextually relevant text
                    </li>
                    <li>
                      <strong>Few-shot Learning:</strong> Can adapt to new tasks
                      with minimal examples
                    </li>
                    <li>
                      <strong>Multimodal:</strong> Advanced models can process
                      text, images, and other data types
                    </li>
                  </ul>
                </div>
              </section>

              <!-- Architecture Section -->
              <section id="architecture" class="content-section">
                <h2 class="section-title">Architecture</h2>

                <div class="architecture-grid">
                  <div class="architecture-item">
                    <h3>Transformer Architecture</h3>
                    <p>
                      Most modern LLMs are based on the transformer
                      architecture, which uses self-attention mechanisms to
                      process sequences of tokens efficiently.
                    </p>
                    <ul>
                      <li>Self-attention layers</li>
                      <li>Feed-forward networks</li>
                      <li>Layer normalization</li>
                      <li>Residual connections</li>
                    </ul>
                  </div>

                  <div class="architecture-item">
                    <h3>Attention Mechanism</h3>
                    <p>
                      The attention mechanism allows the model to focus on
                      relevant parts of the input when generating each token.
                    </p>
                    <ul>
                      <li>Multi-head attention</li>
                      <li>Query, Key, Value matrices</li>
                      <li>Positional encoding</li>
                      <li>Causal masking (for autoregressive models)</li>
                    </ul>
                  </div>
                </div>

                <div class="code-example">
                  <h4>Simplified Attention Formula</h4>
                  <pre><code>Attention(Q, K, V) = softmax(QK^T / ‚àöd_k)V

Where:
- Q: Query matrix
- K: Key matrix  
- V: Value matrix
- d_k: Dimension of key vectors</code></pre>
                </div>
              </section>

              <!-- Training Process Section -->
              <section id="training" class="content-section">
                <h2 class="section-title">Training Process</h2>

                <div class="training-stages">
                  <div class="stage-item">
                    <div class="stage-number">1</div>
                    <div class="stage-content">
                      <h3>Pre-training</h3>
                      <p>
                        Models are trained on massive text corpora using
                        unsupervised learning objectives like next-token
                        prediction.
                      </p>
                      <ul>
                        <li>Billions of parameters</li>
                        <li>Terabytes of text data</li>
                        <li>Months of training time</li>
                        <li>Massive computational resources</li>
                      </ul>
                    </div>
                  </div>

                  <div class="stage-item">
                    <div class="stage-number">2</div>
                    <div class="stage-content">
                      <h3>Fine-tuning</h3>
                      <p>
                        Pre-trained models are adapted for specific tasks or to
                        follow instructions better.
                      </p>
                      <ul>
                        <li>Task-specific datasets</li>
                        <li>Supervised fine-tuning</li>
                        <li>Parameter-efficient methods</li>
                        <li>Domain adaptation</li>
                      </ul>
                    </div>
                  </div>

                  <div class="stage-item">
                    <div class="stage-number">3</div>
                    <div class="stage-content">
                      <h3>Alignment</h3>
                      <p>
                        Models are aligned with human preferences using
                        techniques like RLHF (Reinforcement Learning from Human
                        Feedback).
                      </p>
                      <ul>
                        <li>Human preference data</li>
                        <li>Reward modeling</li>
                        <li>Policy optimization</li>
                        <li>Safety filtering</li>
                      </ul>
                    </div>
                  </div>
                </div>
              </section>

              <!-- Popular Models Section -->
              <section id="models" class="content-section">
                <h2 class="section-title">Popular LLM Models</h2>

                <div class="models-grid">
                  <div class="model-card">
                    <h3>GPT Series</h3>
                    <p><strong>Developer:</strong> OpenAI</p>
                    <p>
                      Autoregressive language models trained on diverse internet
                      text. GPT-4 and ChatGPT have become widely adopted.
                    </p>
                    <div class="model-specs">
                      <span class="spec">175B+ parameters</span>
                      <span class="spec">Multimodal</span>
                      <span class="spec">Commercial</span>
                    </div>
                  </div>

                  <div class="model-card">
                    <h3>Claude</h3>
                    <p><strong>Developer:</strong> Anthropic</p>
                    <p>
                      Constitutional AI approach with emphasis on helpfulness,
                      harmlessness, and honesty.
                    </p>
                    <div class="model-specs">
                      <span class="spec">100B+ parameters</span>
                      <span class="spec">Long context</span>
                      <span class="spec">Commercial</span>
                    </div>
                  </div>

                  <div class="model-card">
                    <h3>LLaMA</h3>
                    <p><strong>Developer:</strong> Meta</p>
                    <p>
                      Open-source foundation models available in multiple sizes
                      for research and commercial use.
                    </p>
                    <div class="model-specs">
                      <span class="spec">7B-70B parameters</span>
                      <span class="spec">Open source</span>
                      <span class="spec">Efficient</span>
                    </div>
                  </div>

                  <div class="model-card">
                    <h3>Gemini</h3>
                    <p><strong>Developer:</strong> Google</p>
                    <p>
                      Multimodal AI model designed to understand and generate
                      text, code, audio, image, and video.
                    </p>
                    <div class="model-specs">
                      <span class="spec">Multimodal</span>
                      <span class="spec">Multiple sizes</span>
                      <span class="spec">Commercial</span>
                    </div>
                  </div>
                </div>
              </section>

              <!-- Applications Section -->
              <section id="applications" class="content-section">
                <h2 class="section-title">Applications</h2>

                <div class="applications-grid">
                  <div class="application-category">
                    <h3>Content Generation</h3>
                    <ul>
                      <li>Creative writing and storytelling</li>
                      <li>Technical documentation</li>
                      <li>Marketing copy and content</li>
                      <li>Code generation and programming</li>
                    </ul>
                  </div>

                  <div class="application-category">
                    <h3>Analysis & Processing</h3>
                    <ul>
                      <li>Text summarization</li>
                      <li>Sentiment analysis</li>
                      <li>Information extraction</li>
                      <li>Document classification</li>
                    </ul>
                  </div>

                  <div class="application-category">
                    <h3>Interactive Systems</h3>
                    <ul>
                      <li>Chatbots and virtual assistants</li>
                      <li>Customer support automation</li>
                      <li>Educational tutoring systems</li>
                      <li>Conversational AI interfaces</li>
                    </ul>
                  </div>

                  <div class="application-category">
                    <h3>Specialized Tasks</h3>
                    <ul>
                      <li>Language translation</li>
                      <li>Code review and debugging</li>
                      <li>Research assistance</li>
                      <li>Data analysis and insights</li>
                    </ul>
                  </div>
                </div>
              </section>

              <!-- Challenges Section -->
              <section id="challenges" class="content-section">
                <h2 class="section-title">Challenges & Limitations</h2>

                <div class="challenges-list">
                  <div class="challenge-item">
                    <h3>Computational Requirements</h3>
                    <p>
                      Training and running LLMs requires significant
                      computational resources, making them expensive to develop
                      and deploy.
                    </p>
                  </div>

                  <div class="challenge-item">
                    <h3>Hallucination</h3>
                    <p>
                      Models can generate plausible-sounding but factually
                      incorrect information, requiring careful verification.
                    </p>
                  </div>

                  <div class="challenge-item">
                    <h3>Bias and Fairness</h3>
                    <p>
                      Models can perpetuate biases present in training data,
                      leading to unfair or discriminatory outputs.
                    </p>
                  </div>

                  <div class="challenge-item">
                    <h3>Context Limitations</h3>
                    <p>
                      Most models have limited context windows, affecting their
                      ability to process very long documents.
                    </p>
                  </div>

                  <div class="challenge-item">
                    <h3>Interpretability</h3>
                    <p>
                      Understanding how models make decisions remains
                      challenging, affecting trust and debugging.
                    </p>
                  </div>

                  <div class="challenge-item">
                    <h3>Data Privacy</h3>
                    <p>
                      Models may inadvertently memorize and reproduce sensitive
                      information from training data.
                    </p>
                  </div>
                </div>
              </section>

              <!-- Implementation Section -->
              <section id="implementation" class="content-section">
                <h2 class="section-title">Real-World Implementation Examples</h2>

                <div class="implementation-tabs">
                  <div class="tab-content">
                    <h3>ü§ñ Chatbot for Customer Support</h3>
                    <div class="code-example">
                      <pre><code>import openai
from datetime import datetime

class CustomerSupportBot:
    def __init__(self, api_key, company_context):
        self.client = openai.OpenAI(api_key=api_key)
        self.company_context = company_context
    
    def get_response(self, customer_message, customer_history=None):
        # Build context-aware system message
        system_msg = f"""You are a helpful customer support agent for {self.company_context['name']}.
        
        Company Info:
        - Business hours: {self.company_context['hours']}
        - Return policy: {self.company_context['return_policy']}
        - Shipping time: {self.company_context['shipping']}
        
        Always be friendly, helpful, and escalate complex issues to human agents."""
        
        messages = [{"role": "system", "content": system_msg}]
        
        # Add customer history if available
        if customer_history:
            messages.extend(customer_history)
        
        messages.append({"role": "user", "content": customer_message})
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            max_tokens=300,
            temperature=0.3  # Lower temperature for consistent responses
        )
        
        return response.choices[0].message.content

# Usage Example
company_info = {
    "name": "TechGadgets Inc",
    "hours": "9 AM - 6 PM EST, Monday-Friday",
    "return_policy": "30-day returns with receipt",
    "shipping": "2-3 business days"
}

bot = CustomerSupportBot("your-api-key", company_info)

# Customer interaction
customer_msg = "Hi, I ordered a laptop 5 days ago but haven't received it yet"
response = bot.get_response(customer_msg)
print(f"Bot: {response}")

# Output: "I understand your concern about your laptop order. Our standard shipping 
# is 2-3 business days, so your order may be slightly delayed. Let me help you track 
# your package. Could you please provide your order number so I can look into this for you?"</code></pre>
                    </div>
                  </div>

                  <div class="tab-content">
                    <h3>üìù Content Generation Tool</h3>
                    <div class="code-example">
                      <pre><code>import openai
import json

class ContentGenerator:
    def __init__(self, api_key):
        self.client = openai.OpenAI(api_key=api_key)
    
    def generate_blog_post(self, topic, target_audience, tone="professional", word_count=800):
        prompt = f"""Write a {word_count}-word blog post about {topic} for {target_audience}.
        
        Requirements:
        - Tone: {tone}
        - Include practical examples
        - Add actionable tips
        - Use headers and bullet points for readability
        - Include a compelling introduction and conclusion
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an expert content writer who creates engaging, well-structured blog posts."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1200,
            temperature=0.7
        )
        
        return response.choices[0].message.content
    
    def generate_social_media_posts(self, content, platforms=["twitter", "linkedin", "facebook"]):
        posts = {}
        
        for platform in platforms:
            if platform == "twitter":
                prompt = f"Convert this content into a Twitter thread (max 280 chars per tweet): {content[:500]}"
                max_tokens = 200
            elif platform == "linkedin":
                prompt = f"Create a professional LinkedIn post from this content: {content[:500]}"
                max_tokens = 300
            else:  # facebook
                prompt = f"Create an engaging Facebook post from this content: {content[:500]}"
                max_tokens = 250
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=max_tokens,
                temperature=0.8
            )
            
            posts[platform] = response.choices[0].message.content
        
        return posts

# Usage Example
generator = ContentGenerator("your-api-key")

# Generate blog post
blog_post = generator.generate_blog_post(
    topic="AI in small businesses",
    target_audience="small business owners",
    tone="friendly and informative"
)

# Generate social media versions
social_posts = generator.generate_social_media_posts(blog_post)

print("Blog Post:", blog_post[:200] + "...")
print("\nTwitter:", social_posts["twitter"])
print("\nLinkedIn:", social_posts["linkedin"][:100] + "...")</code></pre>
                    </div>
                  </div>

                  <div class="tab-content">
                    <h3>üîç Document Analysis System</h3>
                    <div class="code-example">
                      <pre><code>import openai
import PyPDF2
import json
from typing import List, Dict

class DocumentAnalyzer:
    def __init__(self, api_key):
        self.client = openai.OpenAI(api_key=api_key)
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """Extract text from PDF file"""
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()
        return text
    
    def analyze_contract(self, document_text: str) -> Dict:
        """Analyze legal contract and extract key information"""
        prompt = f"""Analyze this contract and extract key information in JSON format:

        Contract Text: {document_text[:2000]}...

        Extract:
        1. Parties involved
        2. Contract duration/dates
        3. Key obligations for each party
        4. Payment terms
        5. Termination clauses
        6. Risk factors or concerning terms

        Format as JSON with clear sections."""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a legal document analysis expert. Extract key information accurately and flag potential issues."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.1  # Very low temperature for accuracy
        )
        
        try:
            # Try to parse as JSON
            return json.loads(response.choices[0].message.content)
        except:
            # If not valid JSON, return as structured text
            return {"analysis": response.choices[0].message.content}
    
    def summarize_research_papers(self, papers: List[str]) -> str:
        """Summarize multiple research papers and find common themes"""
        combined_abstracts = "\n\n".join(papers)
        
        prompt = f"""Analyze these research paper abstracts and provide:
        1. Common themes and findings
        2. Contradictions or disagreements
        3. Gaps in research
        4. Practical implications
        
        Papers:
        {combined_abstracts}"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a research analyst expert at synthesizing academic literature."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=600,
            temperature=0.3
        )
        
        return response.choices[0].message.content

# Usage Example
analyzer = DocumentAnalyzer("your-api-key")

# Analyze a contract
contract_text = """
EMPLOYMENT AGREEMENT

This Employment Agreement is entered into on January 1, 2024, between TechCorp Inc. 
("Company") and John Smith ("Employee").

1. POSITION: Employee will serve as Senior Software Engineer
2. COMPENSATION: $120,000 annually, paid bi-weekly
3. TERM: This agreement is effective for 2 years from the start date
4. TERMINATION: Either party may terminate with 30 days written notice
...
"""

contract_analysis = analyzer.analyze_contract(contract_text)
print("Contract Analysis:")
print(json.dumps(contract_analysis, indent=2))

# Research paper summary example
research_papers = [
    "Abstract 1: Study on AI bias in hiring shows 23% discrimination against female candidates...",
    "Abstract 2: Machine learning algorithms in recruitment reduce bias by 15% when properly calibrated...",
    "Abstract 3: Human-AI collaboration in hiring decisions improves outcomes by 31%..."
]

research_summary = analyzer.summarize_research_papers(research_papers)
print("\nResearch Summary:")
print(research_summary)</code></pre>
                    </div>
                  </div>

                  <div class="tab-content">
                    <h3>üé® Creative Writing Assistant</h3>
                    <div class="code-example">
                      <pre><code>import openai
import random

class CreativeWritingAssistant:
    def __init__(self, api_key):
        self.client = openai.OpenAI(api_key=api_key)
    
    def generate_story_outline(self, genre, theme, characters):
        prompt = f"""Create a detailed story outline for a {genre} story.
        
        Theme: {theme}
        Main Characters: {characters}
        
        Include:
        1. Three-act structure
        2. Character arcs
        3. Key plot points
        4. Potential conflicts
        5. Satisfying resolution
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a professional story editor with expertise in narrative structure."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.8
        )
        
        return response.choices[0].message.content
    
    def improve_dialogue(self, dialogue_text, character_voices):
        prompt = f"""Improve this dialogue to make it more natural and character-specific:

        Original Dialogue:
        {dialogue_text}
        
        Character Voices:
        {character_voices}
        
        Make the dialogue:
        - More natural and conversational
        - Distinct for each character
        - Advance the plot or reveal character
        - Include subtext where appropriate
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a dialogue coach who helps writers create authentic, engaging conversations."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=600,
            temperature=0.7
        )
        
        return response.choices[0].message.content
    
    def generate_character_backstory(self, character_name, role, personality_traits):
        prompt = f"""Create a detailed backstory for this character:
        
        Name: {character_name}
        Role in story: {role}
        Personality: {personality_traits}
        
        Include:
        1. Childhood and formative experiences
        2. Motivations and fears
        3. Relationships with other characters
        4. Skills and weaknesses
        5. Secret or hidden aspect
        6. Character growth potential
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a character development expert who creates rich, complex fictional characters."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=700,
            temperature=0.8
        )
        
        return response.choices[0].message.content

# Usage Example
writer = CreativeWritingAssistant("your-api-key")

# Generate story outline
story_outline = writer.generate_story_outline(
    genre="science fiction thriller",
    theme="the price of technological progress",
    characters="Dr. Sarah Chen (AI researcher), Marcus Rodriguez (tech entrepreneur), ARIA (AI system)"
)

print("Story Outline:")
print(story_outline[:300] + "...\n")

# Improve dialogue
original_dialogue = '''
"We need to shut down the AI system," Sarah said.
"No, we can't do that. It's too valuable," Marcus replied.
"It's dangerous," Sarah said.
"The benefits outweigh the risks," Marcus said.
'''

character_voices = """
Sarah: Cautious scientist, speaks precisely, uses technical terms
Marcus: Ambitious businessman, persuasive, uses profit/loss language
"""

improved_dialogue = writer.improve_dialogue(original_dialogue, character_voices)
print("Improved Dialogue:")
print(improved_dialogue)

# Generate character backstory
backstory = writer.generate_character_backstory(
    character_name="Dr. Sarah Chen",
    role="protagonist AI researcher",
    personality_traits="cautious, brilliant, ethical, haunted by past mistakes"
)

print("\nCharacter Backstory:")
print(backstory[:200] + "...")</code></pre>
                    </div>
              </div>

              <div class="highlight-box info">
                <h3>üí° Implementation Tips</h3>
                <ul>
                  <li><strong>Error Handling:</strong> Always wrap API calls in try-catch blocks</li>
                  <li><strong>Rate Limiting:</strong> Implement delays between requests to avoid hitting API limits</li>
                  <li><strong>Cost Management:</strong> Monitor token usage and set spending limits</li>
                  <li><strong>Security:</strong> Never expose API keys in client-side code</li>
                  <li><strong>Testing:</strong> Test with various inputs to ensure robust responses</li>
                </ul>
              </div>
            </section>

              <!-- Best Practices Section -->
              <section id="best-practices" class="content-section">
                <h2 class="section-title">Best Practices</h2>

                <div class="best-practices-grid">
                  <div class="practice-category">
                    <h3>Prompt Engineering</h3>
                    <ul>
                      <li>Be specific and clear in instructions</li>
                      <li>Provide examples for complex tasks</li>
                      <li>Use system messages to set context</li>
                      <li>Iterate and refine prompts based on results</li>
                    </ul>
                  </div>

                  <div class="practice-category">
                    <h3>Model Selection</h3>
                    <ul>
                      <li>Choose model size based on task complexity</li>
                      <li>Consider latency and cost requirements</li>
                      <li>Evaluate model capabilities for your domain</li>
                      <li>Test multiple models for comparison</li>
                    </ul>
                  </div>

                  <div class="practice-category">
                    <h3>Safety & Ethics</h3>
                    <ul>
                      <li>Implement content filtering and moderation</li>
                      <li>Monitor outputs for bias and harmful content</li>
                      <li>Respect data privacy and user consent</li>
                      <li>Provide transparency about AI usage</li>
                    </ul>
                  </div>

                  <div class="practice-category">
                    <h3>Performance Optimization</h3>
                    <ul>
                      <li>Use caching for repeated queries</li>
                      <li>Implement efficient batching strategies</li>
                      <li>Monitor and optimize token usage</li>
                      <li>Consider model quantization for deployment</li>
                    </ul>
                  </div>
                </div>
              </section>
            </article>
          </div>
        </div>
      </div>
    </main>

    <!-- Footer -->
    <footer class="footer">
      <div class="container">
        <div class="footer-content">
          <p>
            &copy; 2024 Technical Reference. Built with modern web standards.
          </p>
        </div>
      </div>
    </footer>

    <script src="js/main.js"></script>
  </body>
</html>
